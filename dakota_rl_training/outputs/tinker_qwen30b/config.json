{
  "learning_rate": 4e-05,
  "dataset_builder": {
    "model_name": "Qwen/Qwen3-30B-A3B-Instruct-2507",
    "batch_size": 48,
    "group_size": 16,
    "dataset_path": null,
    "eval_path": null,
    "renderer_name": null,
    "max_examples": -1,
    "eval_examples": -1,
    "eval_fraction": 0.1,
    "system_prompt": null,
    "shuffle": true,
    "seed": 42,
    "difficulty_filter": null,
    "task_filter": null,
    "include_hints": true,
    "eval_group_size": 1
  },
  "model_name": "Qwen/Qwen3-30B-A3B-Instruct-2507",
  "max_tokens": 384,
  "temperature": 0.9,
  "compute_post_kl": false,
  "evaluator_builders": [],
  "lora_rank": 32,
  "kl_penalty_coef": 0.0,
  "kl_discount_factor": 0.0,
  "loss_fn": "importance_sampling",
  "num_substeps": 1,
  "wandb_project": "dakota-rl-grammar",
  "wandb_name": "qwen3-30b-dakota",
  "log_path": "dakota_rl_training/outputs/tinker_qwen30b",
  "base_url": null,
  "enable_trace": false,
  "remove_constant_reward_groups": true,
  "eval_every": 20,
  "save_every": 20,
  "load_checkpoint_path": null,
  "async_config": null,
  "stream_minibatch_config": null,
  "num_groups_to_log": 4
}