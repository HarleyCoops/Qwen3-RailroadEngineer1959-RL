# HuggingFace Space Deployment Checklist

##  Space Bundle Ready

All files are prepared in `huggingface_space/`:
-  `app.py` - Gradio interface with proper chat formatting
-  `requirements.txt` - All dependencies specified
-  `README.md` - Space description with metadata

##  What You Need from the Instance

**Answer: NOTHING!** 

The model is already published on HuggingFace Hub at:
- `HarleyCooper/Qwen3-0.6B-Dakota-Grammar-RL`

The Space will download the model directly from HuggingFace Hub when it builds. You don't need to copy any files from your Prime Intellect instance.

**You can safely turn off your instance** - everything needed is on HuggingFace Hub.

##  Deployment Steps

### 1. Create the Space

1. Visit https://huggingface.co/spaces
2. Click **"Create new Space"**
3. Fill in:
   - **Space name**: `HarleyCooper/Dakota-Grammar-Demo` (or your preferred name)
   - **SDK**: Select **"Gradio"**
   - **Hardware**: Select **"GPU"** → Choose **"T4"** or **"A10"** (T4 is enough for 0.6B model)
   - **Visibility**: Public or Private (your choice)
4. Click **"Create Space"**

### 2. Upload Files

After the Space is created, you have two options:

**Option A: Drag & Drop (Easiest)**
1. In the Space file view, drag and drop all files from `huggingface_space/`:
   - `app.py`
   - `requirements.txt`
   - `README.md`
2. Click **"Commit changes"**

**Option B: Git Push**
```bash
cd huggingface_space
git init
git add .
git commit -m "Initial commit"
git remote add origin https://huggingface.co/spaces/HarleyCooper/Dakota-Grammar-Demo
git push -u origin main
```

### 3. Wait for Auto-Deploy

1. Go to the **"Deploy"** tab in your Space
2. Watch the build logs:
   - `pip install` will install dependencies
   - Model will download from HuggingFace Hub
   - `python app.py` will launch the Gradio interface
3. When you see **"Running"** status, your Space is live!

### 4. Test the Space

1. Visit your Space URL: `https://huggingface.co/spaces/HarleyCooper/Dakota-Grammar-Demo`
2. Try the example prompts
3. Adjust temperature/max tokens as needed
4. Share the link!

##  Files Included

```
huggingface_space/
├── app.py              # Gradio interface with chat formatting
├── requirements.txt    # Dependencies (torch, transformers, gradio, etc.)
└── README.md          # Space description and metadata
```

##  Features

-  Loads model from HuggingFace Hub automatically
-  Proper chat formatting with system prompts
-  Repetition penalty to avoid loops
-  Adjustable temperature and max tokens
-  Example prompts included
-  Clean response extraction

##  Tips

- **First build may take 5-10 minutes** (downloading model + dependencies)
- **GPU T4 is sufficient** for 0.6B model
- **If build fails**, check logs in Deploy tab
- **Model is ~1.5GB**, so download time varies

##  You're Ready!

Everything is prepared. Just create the Space and upload the files!

